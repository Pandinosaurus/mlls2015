{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "def qbb(X, y, model, rng):\n",
    "    \n",
    "    X_known = X[~y.mask]\n",
    "    X_unknown = X[y.mask]\n",
    "\n",
    "    clfs = BaggingClassifier(model, n_estimators=100, random_state=rng)\n",
    "\n",
    "    clfs.fit(X_known, y[~y.mask].data)\n",
    "    for es in clfs.estimators_:\n",
    "        setattr(es, \"classes_\", [0, 1])\n",
    "    pc = clfs.predict_proba(X_unknown)\n",
    "\n",
    "    # # for clfs without predict_proba - not used in latest version  \n",
    "    # pc += 1e-8\n",
    "    # fitness = -np.sum(pc * np.log(pc), axis=1)\n",
    "        \n",
    "    p = np.array([clf.predict_proba(X_unknown) for clf in clfs.estimators_])\n",
    "    fitness = np.mean(np.sum(p * np.log(p / pc), axis=2), axis=0)\n",
    "\n",
    "    return X_unknown, fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QBB score visualsation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(666)\n",
    "\n",
    "n = 3000\n",
    "X = np.vstack([rng.uniform(-1, 1, n) for _ in range(2)]).T\n",
    "\n",
    "x1 = np.array([-0.5, 0.5])\n",
    "x2 = np.array([0.5, -0.5])\n",
    "y = np.zeros(3000)\n",
    "y[np.where(np.sqrt(np.sum((X - x1)**2, axis=1)) < 0.3)[0]] = 1\n",
    "y[np.where(np.sqrt(np.sum((X - x2)**2, axis=1)) < 0.2)[0]] = 2\n",
    "\n",
    "g1 = np.where(y == 1)[0]\n",
    "g2 = np.where(y == 2)[0]\n",
    "neg = np.where(np.logical_and(y == 0, np.sqrt(np.sum((X - x1)**2, axis=1)) < 0.5))[0]\n",
    "y[np.where(y == 2)] = 1\n",
    "c = y.copy()\n",
    "\n",
    "warm_start_1 = g1[rng.choice(g1.shape[0], 9, replace=False)]\n",
    "warm_start_2 = g2[rng.choice(g2.shape[0], 1, replace=False)]\n",
    "warm_start_3 = neg[rng.choice(neg.shape[0], 10, replace=False)]\n",
    "\n",
    "warm_start = set(np.hstack([warm_start_1, warm_start_2, warm_start_3])) \n",
    "mask = [i not in warm_start for i in xrange(X.shape[0])]\n",
    "c[list(warm_start)] = -1\n",
    "my = np.ma.array(y, mask=mask)\n",
    "\n",
    "model = GridSearchCV(estimator=SVC(kernel='rbf', probability=True, C=1e6,gamma=100), \n",
    "                     param_grid={\"C\": [1, 1e3, 1e6], \"gamma\": [0.1, 1, 10, 100]})\n",
    "\n",
    "m = GridSearchCV(estimator=SVC(kernel='rbf', probability=True, C=1e6,gamma=100), \n",
    "                 param_grid={\"C\": [1, 1e3, 1e6], \"gamma\": [0.1, 1, 10, 100]})\n",
    "\n",
    "m.fit(X[~np.array(mask)], y[~np.array(mask)])\n",
    "setattr(m, \"classes_\", [0,1])\n",
    "setattr(model, \"classes_\", [0,1])\n",
    "\n",
    "uX, fitness = qbb(X, my, model, rng)\n",
    "\n",
    "f = plt.figure(figsize=(15, 8))\n",
    "\n",
    "ax1 = f.add_subplot(221)\n",
    "ax1.scatter(X[:,0], X[:, 1], c=c, cmap=plt.cm.bwr)\n",
    "red_patch = mpatches.Patch(color='red', label='positive class')\n",
    "white_patch = mpatches.Patch(color='white', label='negative class', ec='k')\n",
    "blue_patch = mpatches.Patch(color='blue', label='warm start')\n",
    "ax1.legend(handles=[red_patch, white_patch, blue_patch], bbox_to_anchor=(0.82, 1), loc=2)\n",
    "ax1.set_title(\"warm start conditions\")\n",
    "\n",
    "ax2 = f.add_subplot(222)\n",
    "cb = ax2.scatter(uX[:, 0], uX[:, 1], c=fitness, cmap=plt.cm.coolwarm)\n",
    "ax2.set_title(\"QBB score\")\n",
    "f.colorbar(cb)\n",
    "\n",
    "ax3 = f.add_subplot(223)\n",
    "v = m.predict_proba(uX)[:, 1]\n",
    "ax3.scatter(uX[:, 0], uX[:, 1], c=v/v.max(), cmap=plt.cm.coolwarm)\n",
    "ax3.set_title(\"Model proba on unknown only\")\n",
    "\n",
    "ax4 = f.add_subplot(224)\n",
    "v = m.predict_proba(X)[:, 0]\n",
    "ax4.scatter(X[:, 0], X[:, 1], c=v/v.max(), cmap=plt.cm.coolwarm)\n",
    "ax4.set_title(\"Model proba on all X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_known = X[~my.mask]\n",
    "X_unknown = np.array([[1.0, 1.0]])\n",
    "\n",
    "clfs = BaggingClassifier(model, n_estimators=10, random_state=rng)\n",
    "\n",
    "clfs.fit(X_known, my[~my.mask].data)\n",
    "for es in clfs.estimators_:\n",
    "    setattr(es, \"classes_\", [0, 1])\n",
    "pc = clfs.predict_proba(X_unknown)\n",
    "\n",
    "print \"ensamble probs \\n\", pc\n",
    "\n",
    "p = np.array([clf.predict_proba(X_unknown) for clf in clfs.estimators_])\n",
    "\n",
    "print \"probs per clf: \\n\", p\n",
    "\n",
    "fitness = np.mean(np.sum(p * np.log(p / pc), axis=2), axis=0)\n",
    "\n",
    "print \"score per clf: \\n\"\n",
    "[clf.score(X, y) for clf in clfs.estimators_]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
