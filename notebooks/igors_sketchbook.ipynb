{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from itertools import product\n",
    "sys.path.append('..')\n",
    "from collections import defaultdict\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from experiments.utils import *\n",
    "pd.set_option(\"display.max_rows\",999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coundn't load 5ht7 uncertainty_sampling 20\n",
      "Coundn't load 5ht7 random_query 20\n",
      "Coundn't load 5ht7 czarnecki 20\n",
      "Couldn't load 5ht7 multiple 20 0.1\n",
      "Couldn't load 5ht7 multiple 20 0.2\n",
      "Couldn't load 5ht7 multiple 20 0.3\n",
      "Couldn't load 5ht7 multiple 20 0.4\n",
      "Couldn't load 5ht7 multiple 20 0.5\n",
      "Couldn't load 5ht7 multiple 20 0.6\n",
      "Couldn't load 5ht7 multiple 20 0.7\n",
      "Couldn't load 5ht7 multiple 20 0.8\n",
      "Couldn't load 5ht7 multiple 20 0.9\n",
      "Couldn't load 5ht7 chen_krause 20 50\n",
      "Couldn't load 5ht7 chen_krause 20 200\n",
      "Couldn't load 5ht7 chen_krause 20 500\n",
      "Coundn't load 5ht7 uncertainty_sampling 50\n",
      "Coundn't load 5ht7 random_query 50\n",
      "Coundn't load 5ht7 czarnecki 50\n",
      "Couldn't load 5ht7 multiple 50 0.1\n",
      "Couldn't load 5ht7 multiple 50 0.2\n",
      "Couldn't load 5ht7 multiple 50 0.3\n",
      "Couldn't load 5ht7 multiple 50 0.4\n",
      "Couldn't load 5ht7 multiple 50 0.5\n",
      "Couldn't load 5ht7 multiple 50 0.6\n",
      "Couldn't load 5ht7 multiple 50 0.7\n",
      "Couldn't load 5ht7 multiple 50 0.8\n",
      "Couldn't load 5ht7 multiple 50 0.9\n",
      "Couldn't load 5ht7 chen_krause 50 50\n",
      "Couldn't load 5ht7 chen_krause 50 200\n",
      "Couldn't load 5ht7 chen_krause 50 500\n",
      "Coundn't load hiv_integrase uncertainty_sampling 20\n",
      "Coundn't load hiv_integrase random_query 20\n",
      "Coundn't load hiv_integrase czarnecki 20\n",
      "Couldn't load hiv_integrase multiple 20 0.1\n",
      "Couldn't load hiv_integrase multiple 20 0.2\n",
      "Couldn't load hiv_integrase multiple 20 0.3\n",
      "Couldn't load hiv_integrase multiple 20 0.4\n",
      "Couldn't load hiv_integrase multiple 20 0.5\n",
      "Couldn't load hiv_integrase multiple 20 0.6\n",
      "Couldn't load hiv_integrase multiple 20 0.7\n",
      "Couldn't load hiv_integrase multiple 20 0.8\n",
      "Couldn't load hiv_integrase multiple 20 0.9\n",
      "Couldn't load hiv_integrase chen_krause 20 50\n",
      "Couldn't load hiv_integrase chen_krause 20 200\n",
      "Couldn't load hiv_integrase chen_krause 20 500\n",
      "Coundn't load hiv_integrase uncertainty_sampling 50\n",
      "Coundn't load hiv_integrase random_query 50\n",
      "Coundn't load hiv_integrase czarnecki 50\n",
      "Couldn't load hiv_integrase multiple 50 0.1\n",
      "Couldn't load hiv_integrase multiple 50 0.2\n",
      "Couldn't load hiv_integrase multiple 50 0.3\n",
      "Couldn't load hiv_integrase multiple 50 0.4\n",
      "Couldn't load hiv_integrase multiple 50 0.5\n",
      "Couldn't load hiv_integrase multiple 50 0.6\n",
      "Couldn't load hiv_integrase multiple 50 0.7\n",
      "Couldn't load hiv_integrase multiple 50 0.8\n",
      "Couldn't load hiv_integrase multiple 50 0.9\n",
      "Couldn't load hiv_integrase chen_krause 50 50\n",
      "Couldn't load hiv_integrase chen_krause 50 200\n",
      "Couldn't load hiv_integrase chen_krause 50 500\n",
      "Coundn't load hiv_integrase uncertainty_sampling 100\n",
      "Coundn't load hiv_integrase random_query 100\n",
      "Coundn't load hiv_integrase czarnecki 100\n",
      "Couldn't load hiv_integrase multiple 100 0.1\n",
      "Couldn't load hiv_integrase multiple 100 0.2\n",
      "Couldn't load hiv_integrase multiple 100 0.3\n",
      "Couldn't load hiv_integrase multiple 100 0.4\n",
      "Couldn't load hiv_integrase multiple 100 0.5\n",
      "Couldn't load hiv_integrase multiple 100 0.6\n",
      "Couldn't load hiv_integrase multiple 100 0.7\n",
      "Couldn't load hiv_integrase multiple 100 0.8\n",
      "Couldn't load hiv_integrase multiple 100 0.9\n",
      "Couldn't load hiv_integrase chen_krause 100 50\n",
      "Couldn't load hiv_integrase chen_krause 100 200\n",
      "Couldn't load hiv_integrase chen_krause 100 500\n",
      "Coundn't load h1 uncertainty_sampling 20\n",
      "Coundn't load h1 random_query 20\n",
      "Coundn't load h1 czarnecki 20\n",
      "Couldn't load h1 multiple 20 0.1\n",
      "Couldn't load h1 multiple 20 0.2\n",
      "Couldn't load h1 multiple 20 0.3\n",
      "Couldn't load h1 multiple 20 0.4\n",
      "Couldn't load h1 multiple 20 0.5\n",
      "Couldn't load h1 multiple 20 0.6\n",
      "Couldn't load h1 multiple 20 0.7\n",
      "Couldn't load h1 multiple 20 0.8\n",
      "Couldn't load h1 multiple 20 0.9\n",
      "Couldn't load h1 chen_krause 20 50\n",
      "Couldn't load h1 chen_krause 20 200\n",
      "Couldn't load h1 chen_krause 20 500\n",
      "Coundn't load h1 uncertainty_sampling 50\n",
      "Coundn't load h1 random_query 50\n",
      "Coundn't load h1 czarnecki 50\n",
      "Couldn't load h1 multiple 50 0.1\n",
      "Couldn't load h1 multiple 50 0.2\n",
      "Couldn't load h1 multiple 50 0.3\n",
      "Couldn't load h1 multiple 50 0.4\n",
      "Couldn't load h1 multiple 50 0.5\n",
      "Couldn't load h1 multiple 50 0.6\n",
      "Couldn't load h1 multiple 50 0.7\n",
      "Couldn't load h1 multiple 50 0.8\n",
      "Couldn't load h1 multiple 50 0.9\n",
      "Couldn't load h1 chen_krause 50 50\n",
      "Couldn't load h1 chen_krause 50 200\n",
      "Couldn't load h1 chen_krause 50 500\n",
      "Coundn't load h1 uncertainty_sampling 100\n",
      "Coundn't load h1 random_query 100\n",
      "Coundn't load h1 czarnecki 100\n",
      "Couldn't load h1 multiple 100 0.1\n",
      "Couldn't load h1 multiple 100 0.2\n",
      "Couldn't load h1 multiple 100 0.3\n",
      "Couldn't load h1 multiple 100 0.4\n",
      "Couldn't load h1 multiple 100 0.5\n",
      "Couldn't load h1 multiple 100 0.6\n",
      "Couldn't load h1 multiple 100 0.7\n",
      "Couldn't load h1 multiple 100 0.8\n",
      "Couldn't load h1 multiple 100 0.9\n",
      "Couldn't load h1 chen_krause 100 50\n",
      "Couldn't load h1 chen_krause 100 200\n",
      "Couldn't load h1 chen_krause 100 500\n",
      "Coundn't load cathepsin uncertainty_sampling 20\n",
      "Coundn't load cathepsin random_query 20\n",
      "Coundn't load cathepsin czarnecki 20\n",
      "Couldn't load cathepsin multiple 20 0.1\n",
      "Couldn't load cathepsin multiple 20 0.2\n",
      "Couldn't load cathepsin multiple 20 0.3\n",
      "Couldn't load cathepsin multiple 20 0.4\n",
      "Couldn't load cathepsin multiple 20 0.5\n",
      "Couldn't load cathepsin multiple 20 0.6\n",
      "Couldn't load cathepsin multiple 20 0.7\n",
      "Couldn't load cathepsin multiple 20 0.8\n",
      "Couldn't load cathepsin multiple 20 0.9\n",
      "Couldn't load cathepsin chen_krause 20 50\n",
      "Couldn't load cathepsin chen_krause 20 200\n",
      "Couldn't load cathepsin chen_krause 20 500\n",
      "Coundn't load cathepsin uncertainty_sampling 50\n",
      "Coundn't load cathepsin random_query 50\n",
      "Coundn't load cathepsin czarnecki 50\n",
      "Couldn't load cathepsin multiple 50 0.1\n",
      "Couldn't load cathepsin multiple 50 0.2\n",
      "Couldn't load cathepsin multiple 50 0.3\n",
      "Couldn't load cathepsin multiple 50 0.4\n",
      "Couldn't load cathepsin multiple 50 0.5\n",
      "Couldn't load cathepsin multiple 50 0.6\n",
      "Couldn't load cathepsin multiple 50 0.7\n",
      "Couldn't load cathepsin multiple 50 0.8\n",
      "Couldn't load cathepsin multiple 50 0.9\n",
      "Couldn't load cathepsin chen_krause 50 50\n",
      "Couldn't load cathepsin chen_krause 50 200\n",
      "Couldn't load cathepsin chen_krause 50 500\n",
      "Coundn't load cathepsin uncertainty_sampling 100\n",
      "Coundn't load cathepsin random_query 100\n",
      "Coundn't load cathepsin czarnecki 100\n",
      "Couldn't load cathepsin multiple 100 0.1\n",
      "Couldn't load cathepsin multiple 100 0.2\n",
      "Couldn't load cathepsin multiple 100 0.3\n",
      "Couldn't load cathepsin multiple 100 0.4\n",
      "Couldn't load cathepsin multiple 100 0.5\n",
      "Couldn't load cathepsin multiple 100 0.6\n",
      "Couldn't load cathepsin multiple 100 0.7\n",
      "Couldn't load cathepsin multiple 100 0.8\n",
      "Couldn't load cathepsin multiple 100 0.9\n",
      "Couldn't load cathepsin chen_krause 100 50\n",
      "Couldn't load cathepsin chen_krause 100 200\n",
      "Couldn't load cathepsin chen_krause 100 500\n",
      "Coundn't load M1 uncertainty_sampling 20\n",
      "Coundn't load M1 random_query 20\n",
      "Coundn't load M1 czarnecki 20\n",
      "Couldn't load M1 multiple 20 0.1\n",
      "Couldn't load M1 multiple 20 0.2\n",
      "Couldn't load M1 multiple 20 0.3\n",
      "Couldn't load M1 multiple 20 0.4\n",
      "Couldn't load M1 multiple 20 0.5\n",
      "Couldn't load M1 multiple 20 0.6\n",
      "Couldn't load M1 multiple 20 0.7\n",
      "Couldn't load M1 multiple 20 0.8\n",
      "Couldn't load M1 multiple 20 0.9\n",
      "Couldn't load M1 chen_krause 20 50\n",
      "Couldn't load M1 chen_krause 20 200\n",
      "Couldn't load M1 chen_krause 20 500\n",
      "Coundn't load M1 uncertainty_sampling 50\n",
      "Coundn't load M1 random_query 50\n",
      "Coundn't load M1 czarnecki 50\n",
      "Couldn't load M1 multiple 50 0.1\n",
      "Couldn't load M1 multiple 50 0.2\n",
      "Couldn't load M1 multiple 50 0.3\n",
      "Couldn't load M1 multiple 50 0.4\n",
      "Couldn't load M1 multiple 50 0.5\n",
      "Couldn't load M1 multiple 50 0.6\n",
      "Couldn't load M1 multiple 50 0.7\n",
      "Couldn't load M1 multiple 50 0.8\n",
      "Couldn't load M1 multiple 50 0.9\n",
      "Couldn't load M1 chen_krause 50 50\n",
      "Couldn't load M1 chen_krause 50 200\n",
      "Couldn't load M1 chen_krause 50 500\n",
      "Coundn't load M1 uncertainty_sampling 100\n",
      "Coundn't load M1 random_query 100\n",
      "Coundn't load M1 czarnecki 100\n",
      "Couldn't load M1 multiple 100 0.1\n",
      "Couldn't load M1 multiple 100 0.2\n",
      "Couldn't load M1 multiple 100 0.3\n",
      "Couldn't load M1 multiple 100 0.4\n",
      "Couldn't load M1 multiple 100 0.5\n",
      "Couldn't load M1 multiple 100 0.6\n",
      "Couldn't load M1 multiple 100 0.7\n",
      "Couldn't load M1 multiple 100 0.8\n",
      "Couldn't load M1 multiple 100 0.9\n",
      "Couldn't load M1 chen_krause 100 50\n",
      "Couldn't load M1 chen_krause 100 200\n",
      "Couldn't load M1 chen_krause 100 500\n",
      "Coundn't load 5ht6 uncertainty_sampling 20\n",
      "Coundn't load 5ht6 random_query 20\n",
      "Couldn't load 5ht6 multiple 20 0.1\n",
      "Couldn't load 5ht6 multiple 20 0.2\n",
      "Couldn't load 5ht6 multiple 20 0.3\n",
      "Couldn't load 5ht6 multiple 20 0.4\n",
      "Couldn't load 5ht6 multiple 20 0.5\n",
      "Couldn't load 5ht6 multiple 20 0.6\n",
      "Couldn't load 5ht6 multiple 20 0.7\n",
      "Couldn't load 5ht6 multiple 20 0.8\n",
      "Couldn't load 5ht6 multiple 20 0.9\n",
      "Couldn't load 5ht6 chen_krause 20 50\n",
      "Couldn't load 5ht6 chen_krause 20 200\n",
      "Couldn't load 5ht6 chen_krause 20 500\n",
      "Coundn't load 5ht6 uncertainty_sampling 50\n",
      "Coundn't load 5ht6 random_query 50\n",
      "Coundn't load 5ht6 czarnecki 50\n",
      "Couldn't load 5ht6 multiple 50 0.1\n",
      "Couldn't load 5ht6 multiple 50 0.2\n",
      "Couldn't load 5ht6 multiple 50 0.3\n",
      "Couldn't load 5ht6 multiple 50 0.4\n",
      "Couldn't load 5ht6 multiple 50 0.5\n",
      "Couldn't load 5ht6 multiple 50 0.6\n",
      "Couldn't load 5ht6 multiple 50 0.7\n",
      "Couldn't load 5ht6 multiple 50 0.8\n",
      "Couldn't load 5ht6 multiple 50 0.9\n",
      "Couldn't load 5ht6 chen_krause 50 50\n",
      "Couldn't load 5ht6 chen_krause 50 200\n",
      "Couldn't load 5ht6 chen_krause 50 500\n",
      "Coundn't load 5ht6 uncertainty_sampling 100\n",
      "Coundn't load 5ht6 random_query 100\n",
      "Coundn't load 5ht6 czarnecki 100\n",
      "Couldn't load 5ht6 multiple 100 0.1\n",
      "Couldn't load 5ht6 multiple 100 0.2\n",
      "Couldn't load 5ht6 multiple 100 0.3\n",
      "Couldn't load 5ht6 multiple 100 0.4\n",
      "Couldn't load 5ht6 multiple 100 0.5\n",
      "Couldn't load 5ht6 multiple 100 0.6\n",
      "Couldn't load 5ht6 multiple 100 0.7\n",
      "Couldn't load 5ht6 multiple 100 0.8\n",
      "Couldn't load 5ht6 multiple 100 0.9\n",
      "Couldn't load 5ht6 chen_krause 100 50\n",
      "Couldn't load 5ht6 chen_krause 100 200\n",
      "Couldn't load 5ht6 chen_krause 100 500\n",
      "Loaded 43/756\n"
     ]
    }
   ],
   "source": [
    "experiments_MACCSFP = load_results(fingerprint=\"PubchemFP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps = experiments_MACCSFP.values()[0]\n",
    "len(exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.802662891599\n",
      "0.806230030874\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n",
      "0.802662891599\n"
     ]
    }
   ],
   "source": [
    "for e in exps:\n",
    "    print e.misc['mean_monitor']['wac_score_concept'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00362988902349\n",
      "0.00448398055843\n",
      "0.00200599130245\n",
      "0.00491791416085\n",
      "0.00390911125606\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    var = []\n",
    "    for e in exps:\n",
    "        var.append(e.monitors[i]['wac_score_concept'][-1])\n",
    "    print np.std(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_results(fingerprint=\"ExtFP\", batch_sizes=[20, 50, 100]):\n",
    "\n",
    "    proteins = ['5ht7','hiv_integrase','h1','cathepsin','M1', '5ht6']\n",
    "    strategies = ['uncertainty_sampling', 'random_query', 'czarnecki']\n",
    "    experiments = {p+'_'+str(bs): [] for p in proteins for bs in batch_sizes}\n",
    "    n_loaded = 0\n",
    "    n_all = len(proteins) * len(batch_sizes) * (len(strategies) + 4*9 + 3) # gtfo pisałem na szybko\n",
    "    for p in proteins:\n",
    "        for batch_size in batch_sizes:\n",
    "            for strat in strategies:\n",
    "                try:\n",
    "                    exp_name = \"fit_SVMTAN_%s_%s_%s_%s\" % (strat, p, fingerprint, str(batch_size))\n",
    "                    exp = get_experiment_results(exp_name)\n",
    "                    experiments[p+'_'+str(batch_size)] += exp.experiments\n",
    "                    n_loaded += 1\n",
    "                except:\n",
    "                    print \"Coundn't load\", p, strat, batch_size\n",
    "                    continue\n",
    "            for c in list(np.linspace(0.1, 0.9, 9)):\n",
    "                \n",
    "                exp_name = \"fit_SVMTAN_multiple_pick_best_prim_c_%.2f_%s_%s_%s\" % (c, p, fingerprint, str(batch_size))\n",
    "                \n",
    "                if fingerprint == \"ExtFP\":\n",
    "                     exp_name = \"fit_SVMTAN_multiple_pick_best_c_%.2f_%s_%s_%s\" % (c, p, fingerprint, str(batch_size))\n",
    "                \n",
    "                try:\n",
    "                    exp = get_experiment_results(exp_name)\n",
    "                    assert len(exp.experiments) == 1\n",
    "                    experiments[p+'_'+str(batch_size)].append(exp.experiments[0])\n",
    "                    n_loaded += 1\n",
    "                except:\n",
    "                    print \"Couldn't load\", p, \"multiple\", batch_size, c\n",
    "                    continue\n",
    "\n",
    "                exp_name = \"fit_SVMTAN_czarnecki_two_clusters_c_%.2f_%s_%s_%s\" % (c, p, fingerprint, str(batch_size))\n",
    " \n",
    "                try:\n",
    "                    exp = get_experiment_results(exp_name)\n",
    "                    assert len(exp.experiments) == 1\n",
    "                    experiments[p+'_'+str(batch_size)].append(exp.experiments[0])\n",
    "                    n_loaded += 1\n",
    "                except:\n",
    "                    print \"Couldn't load\", p, \"multiple\", batch_size, c\n",
    "                    continue\n",
    "                    \n",
    "                exp_name = \"fit_SVMTAN_czarnecki_two_clusters_sorensen_c_%.2f_%s_%s_%s\" % (c, p, fingerprint, str(batch_size))\n",
    " \n",
    "                try:\n",
    "                    exp = get_experiment_results(exp_name)\n",
    "                    # Hack to make it distinguishable\n",
    "                    for experiment in exp.experiments:\n",
    "                        experiment.config[\"strategy\"] = \"czarnecki_two_clusters_sorensen\"\n",
    "                        \n",
    "                    assert len(exp.experiments) == 1\n",
    "                    experiments[p+'_'+str(batch_size)].append(exp.experiments[0])\n",
    "                    n_loaded += 1\n",
    "                except:\n",
    "                    print \"Couldn't load\", p, \"czarnecki_two_clusters_sorensen\", batch_size, c\n",
    "                    continue\n",
    "                    \n",
    "                    \n",
    "                exp_name = \"fit_SVMTAN_quasi_greedy_batch_c_%.2f_%s_%s_%s\" % (c, p, fingerprint, str(batch_size))\n",
    "                try:\n",
    "                    exp = get_experiment_results(exp_name)\n",
    "                    assert len(exp.experiments) == 1\n",
    "                    experiments[p+'_'+str(batch_size)].append(exp.experiments[0])\n",
    "                    n_loaded += 1\n",
    "                except:\n",
    "                    print \"Couldn't load\", p, \"quasi_greedy\", batch_size, c\n",
    "                    continue\n",
    "\n",
    "            for h in [50,200,500]:\n",
    "                exp_name = \"fit_SVMTAN_multiple_pick_best_h_%d_%s_%s_%s\" % (h, p, fingerprint, str(batch_size))\n",
    "                try:\n",
    "                    exp = get_experiment_results(exp_name)\n",
    "                    assert len(exp.experiments) == 1\n",
    "                    experiments[p+'_'+str(batch_size)].append(exp.experiments[0])\n",
    "                    n_loaded += 1\n",
    "                except:\n",
    "                    print \"Couldn't load\", p, \"chen_krause\", batch_size, h\n",
    "                    continue\n",
    "    \n",
    "    print \"Loaded %d/%d\" % (n_loaded, n_all)\n",
    "    return experiments\n",
    "\n",
    "def count_strat_experiments(experiments):\n",
    "    strats = []\n",
    "\n",
    "    for key, protein_experiments in experiments.iteritems():\n",
    "        for e in protein_experiments:\n",
    "            strats.append(e.config['strategy'])\n",
    "\n",
    "    return Counter(strats)\n",
    "\n",
    "def get_best_per_strategy(experiments, metric='auc_wac_score_concept'):\n",
    "\n",
    "    strategies = ['chen_krause', 'uncertainty_sampling', 'random_query', 'czarnecki', 'quasi_greedy_batch',\n",
    "                  'multiple_pick_best', 'czarnecki_two_clusters', 'czarnecki_two_clusters_sorensen']\n",
    "    best_protein_exp = {k: {s: [None, 0] for s in strategies} for k in experiments.keys()}\n",
    "    for key, protein_experiments in experiments.iteritems():\n",
    "        for e in protein_experiments:\n",
    "            strat = e.config['strategy']\n",
    "            if e.results[metric] >= best_protein_exp[key][strat][1]:\n",
    "                best_protein_exp[key][strat][0] = e\n",
    "                best_protein_exp[key][strat][1] = e.results[metric]\n",
    "\n",
    "    return {k: {s: e[0] for s, e in exps.iteritems()} for k, exps in best_protein_exp.iteritems()}\n",
    "\n",
    "\n",
    "def plot_monitors(experiments, keys='metrics', folds='mean', figsize=(15,15), \n",
    "                  filter_out=['czarnecki', 'quasi_greedy_batch']):\n",
    "    import matplotlib.pylab as plt\n",
    "\n",
    "    assert folds in ['all', 'mean']\n",
    "    assert keys in ['metrics', 'times']\n",
    "\n",
    "    if keys == 'times':\n",
    "        include = ['unlabeled_test_times',\n",
    "                   'grid_times',\n",
    "                   'strat_times',\n",
    "                   'concept_test_times']\n",
    "    elif keys == \"metrics\":\n",
    "        include = []\n",
    "        for metr in [\"wac_score\"]:\n",
    "            for dataset in ['concept', 'cluster_B_concept']:\n",
    "#                             [\"concept\", \"unlabeled\", \"cluster_A_concept\", \"cluster_B_concept\",\n",
    "#                             \"cluster_A_unlabeled\", \"cluster_B_unlabeled\"]:\n",
    "                include.append(metr+\"_\"+dataset)\n",
    "\n",
    "\n",
    "    keys = [k for k in experiments.values()[0].monitors[0].keys() if k in include]\n",
    "\n",
    "    f, axes = plt.subplots(len(keys), 1)\n",
    "    f.set_figheight(figsize[1])\n",
    "    f.set_figwidth(figsize[0])\n",
    "\n",
    "    assert folds == 'mean'\n",
    "\n",
    "    if folds == 'mean':\n",
    "        for ax, key in zip(axes, keys):\n",
    "            for strat, e in experiments.iteritems():\n",
    "                if e is None or strat in filter_out:\n",
    "                    continue\n",
    "                pd.DataFrame({strat: e.misc['mean_monitor'][key]}).plot(title=key, ax=ax)\n",
    "                ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "    else:\n",
    "        for ax, key in zip(axes, keys):\n",
    "            for e in experiments:\n",
    "                for mon in e.monitors:\n",
    "                    pd.DataFrame({e.name: mon[key]}).plot(title=key, ax=ax)\n",
    "                    ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_wins(experiments, metric = 'auc_wac_score_concept', filter_out=[]):\n",
    "\n",
    "    strategies = ['chen_krause', \n",
    "                  'uncertainty_sampling', \n",
    "                  'quasi_greedy_batch', \n",
    "                  'random_query', \n",
    "                  'multiple_pick_best',\n",
    "                  'czarnecki', \n",
    "                  'czarnecki_two_clusters', \n",
    "                  'czarnecki_two_clusters_sorensen']\n",
    "\n",
    "    wins = {strat: 0 for strat in strategies if strat not in filter_out}\n",
    "    diffs = defaultdict(float)\n",
    "    best_exps = {p: None for p in experiments.keys()}\n",
    "\n",
    "    for p, protein_exps in experiments.iteritems():\n",
    "        \n",
    "        if len(protein_exps) != 0:\n",
    "            best_score = (None, -np.inf)\n",
    "\n",
    "            for e in protein_exps:\n",
    "                if e.config['strategy'] in filter_out:\n",
    "                    continue\n",
    "                    \n",
    "                if metric[:5] == 'fast_':\n",
    "                    metric = metric[5:]\n",
    "                    metric_scores = e.misc['mean_monitor'][metric]\n",
    "                    high_score = max(metric_scores)\n",
    "                    ind = np.where(metric_scores >= 0.9 * high_score)[0][0]\n",
    "                    exp_score = e.monitors[0]['iter'] - ind\n",
    "                elif 'auc' not in metric and 'mean' not in metric:\n",
    "                    exp_score = e.misc['mean_monitor'][metric][-1]\n",
    "                else:\n",
    "                    exp_score = e.results[metric]\n",
    "                    \n",
    "                if exp_score >= best_score[1]:\n",
    "                    best_score = (e.config['strategy'], exp_score)\n",
    "                    best_exps[p] = e\n",
    "\n",
    "            if best_score[0] <= 0:\n",
    "                print best_score\n",
    "            wins[best_score[0]] += 1\n",
    "            if 'auc' not in metric and 'mean' not in metric:\n",
    "                diffs[best_score[0]] += best_score[1] - max([e.misc['mean_monitor'][metric][-1] for e in protein_exps\n",
    "                                                             if e.config['strategy'] != best_score[0]])\n",
    "            else:\n",
    "                diffs[best_score[0]] += best_score[1] - max([e.results[metric] for e in protein_exps\n",
    "                                                             if e.config['strategy'] != best_score[0]])\n",
    "        else:\n",
    "            print \"Zero length for \"+p\n",
    "\n",
    "            \n",
    "    for k in wins:\n",
    "        diffs[k] /= max(1.0, float(wins[k]))\n",
    "         \n",
    "            \n",
    "    keys = wins.keys()\n",
    "    keys_proteins = best_exps.keys()\n",
    "    \n",
    "    wins_df = pd.DataFrame([(wins[key], diffs[key]) for key in wins.keys()], index=keys)\n",
    "    wins_df.columns = ['score', 'avg_diff']\n",
    "\n",
    "    which_df = pd.DataFrame([(e.config['strategy']) for p, e in best_exps.iteritems()], index=keys_proteins)\n",
    "    which_df.columns = [\"best strategy\"]\n",
    "\n",
    "    return wins_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pairwise_count_wins(experiments, metric='auc_wac_score_concept', compare=None):\n",
    "\n",
    "    strategies = ['chen_krause', 'uncertainty_sampling', 'quasi_greedy_batch', 'random_query', 'multiple_pick_best',\n",
    "              'czarnecki', 'czarnecki_two_clusters', 'czarnecki_two_clusters_sorensen']\n",
    "\n",
    "    scores = defaultdict(float)\n",
    "    wins = defaultdict(float)\n",
    "    diffs = defaultdict(float)\n",
    "    \n",
    "    if compare is None:\n",
    "        compare = strategies\n",
    "\n",
    "    for p, protein_exps in experiments.iteritems():\n",
    "        # Get scores for all strategies\n",
    "        strategy_scores = defaultdict(float)\n",
    "        for e in protein_exps:\n",
    "            \n",
    "            if e.config[\"strategy\"] in compare:\n",
    "            \n",
    "                if metric[:5] == 'fast_':\n",
    "                    metric = metric[5:]\n",
    "                    metric_scores = e.misc['mean_monitor'][metric]\n",
    "                    high_score = max(metric_scores)\n",
    "                    ind = np.where(metric_scores >= 0.9 * high_score)[0][0]\n",
    "                    exp_score = e.monitors[0]['iter'] - ind\n",
    "                elif 'auc' not in metric and 'mean' not in metric:\n",
    "                    exp_score = e.misc['mean_monitor'][metric][-1]\n",
    "                else:\n",
    "                    exp_score = e.results[metric]\n",
    "\n",
    "                if e.config[\"strategy\"] in ['quasi_greedy_batch', 'multiple_pick_best']:\n",
    "                    strat = e.config[\"strategy\"] + \"_\" + str(e.config['strategy_kwargs']['c'])\n",
    "                elif e.config[\"strategy\"] in ['czarnecki_two_clusters']:\n",
    "                    strat = \"czarnecki_tc_\" + str(e.config['strategy_kwargs']['c'])\n",
    "                elif e.config[\"strategy\"] in ['czarnecki_two_clusters_sorensen']:\n",
    "                    strat = \"czarnecki_tc_sor_\" + str(e.config['strategy_kwargs']['c'])\n",
    "                elif e.config[\"strategy\"] == 'chen_krause':\n",
    "                    strat = e.config[\"strategy\"] + \"_\" + str(e.config['strategy_projection_h'])\n",
    "                else:\n",
    "                    strat = e.config[\"strategy\"]\n",
    "\n",
    "                strategy_scores[strat] = max(strategy_scores[strat], exp_score)\n",
    "        \n",
    "        for strat1, strat2 in product(strategy_scores, strategy_scores):\n",
    "            # We don't compare same \"types\" of strtegies\n",
    "            if strat1!=strat2 and (strat1[:5] != strat2[:5] or strat1[:9] == \"czarnecki\"):\n",
    "                if strategy_scores[strat1] > strategy_scores[strat2]:\n",
    "                    wins[strat1 + \" vs \" + strat2] += 1 \n",
    "                    scores[strat1 + \" vs \" + strat2] += 1\n",
    "                    diffs[strat1 + \" vs \" + strat2] += strategy_scores[strat1] - strategy_scores[strat2]\n",
    "                else:\n",
    "                    scores[strat1 + \" vs \" + strat2] -= 1\n",
    "                    #diffs[strat1 + \" vs \" + strat2] += strategy_scores[strat1] - strategy_scores[strat2]\n",
    "        \n",
    "        for k in wins:\n",
    "            diffs[k] /= max(1.0, abs(float(wins[k])))\n",
    "        \n",
    "    keys = scores.keys()\n",
    "    df = pd.DataFrame([(scores[key], diffs[key]) for key in keys], index=keys)\n",
    "    df.columns = ['score', 'avg_diff']\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def average_ranking(experiments, metric=\"auc_wac_score_concept\", filter_out=[]):\n",
    "    \n",
    "    strategies = ['chen_krause', 'uncertainty_sampling', 'quasi_greedy_batch', 'random_query', \n",
    "                  'multiple_pick_best', 'czarnecki', 'czarnecki_two_clusters', 'czarnecki_two_clusters_sorensen']\n",
    "    \n",
    "    rank = defaultdict(list)\n",
    "    \n",
    "    for p, protein_exps in experiments.iteritems():\n",
    "\n",
    "        if len(protein_exps) != 0:\n",
    "            scores = defaultdict(list)\n",
    "            for e in protein_exps:\n",
    "\n",
    "                if e.config['strategy'] in filter_out:\n",
    "                    continue\n",
    "                  \n",
    "                if metric[:5] == 'fast_':\n",
    "                    metric = metric[5:]\n",
    "                    metric_scores = e.misc['mean_monitor'][metric]\n",
    "                    high_score = max(metric_scores)\n",
    "                    ind = np.where(metric_scores >= 0.9 * high_score)[0][0]\n",
    "                    exp_score = e.monitors[0]['iter'] - ind\n",
    "                elif metric[:12] == 'partial_mean':\n",
    "                    print \"test\"\n",
    "                    metric = metric[13:]\n",
    "                    exp_score = np.mean(e.misc['mean_monitor'][metric][-15:-5])\n",
    "                elif 'auc' not in metric and 'mean' not in metric:\n",
    "                    exp_score = e.misc['mean_monitor'][metric][-1]\n",
    "                else:\n",
    "                    exp_score = e.results[metric]\n",
    "                    \n",
    "                scores[e.config['strategy']].append(exp_score)\n",
    "\n",
    "            for k, s in scores.iteritems():\n",
    "                scores[k] = np.max(s)\n",
    "\n",
    "            # it's a kind of magic\n",
    "            for i, strat in enumerate(OrderedDict(sorted(scores.items(), key=lambda t: t[1], reverse=True)).keys()): \n",
    "                rank[strat].append(i+1)\n",
    "\n",
    "        else:\n",
    "            print \"Zero length for \" + p\n",
    "\n",
    "    for strat, ranks in rank.iteritems():\n",
    "        rank[strat] = np.mean(ranks, dtype=float)\n",
    "    \n",
    "    strats = rank.keys()\n",
    "    df = pd.DataFrame([rank[key] for key in strats], index=strats)\n",
    "    df.columns = ['average_rank']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_experiments(experiment_dicts):\n",
    "    exp_keys = experiment_dicts[0].keys()\n",
    "    for e in experiment_dicts:\n",
    "        assert e.keys() == exp_keys\n",
    "\n",
    "    joined_experiments = defaultdict(list)\n",
    "    for e in experiment_dicts:\n",
    "        for k in exp_keys:\n",
    "            joined_experiments[k] += e[k]\n",
    "            \n",
    "    return joined_experiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
